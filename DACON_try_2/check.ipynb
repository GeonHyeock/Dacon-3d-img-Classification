{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be406ae1",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "909f9af1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T06:41:00.380585Z",
     "start_time": "2022-08-10T06:41:00.374325Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim, cuda\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from model_GH import GH\n",
    "from model_GH import pointnetloss\n",
    "import pickle\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "class GH_Dataset(torch.utils.data.Dataset): \n",
    "    def __init__(self,X,Y):\n",
    "        self.x_data = torch.from_numpy(X).type(dtype=torch.float32)\n",
    "        self.y_data = torch.tensor(Y).resize_(len(X),1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a2f0b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'GH_Dataset' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/inhamath/dacon/GH_DACON_2022_08/check.ipynb 셀 3\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B165.246.121.113/home/inhamath/dacon/GH_DACON_2022_08/check.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/inhamath/dacon\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B165.246.121.113/home/inhamath/dacon/GH_DACON_2022_08/check.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/GH_DACON_2022_08/train_dataset.pickle\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B165.246.121.113/home/inhamath/dacon/GH_DACON_2022_08/check.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     train_dataset \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B165.246.121.113/home/inhamath/dacon/GH_DACON_2022_08/check.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/GH_DACON_2022_08/test_dataset.pickle\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B165.246.121.113/home/inhamath/dacon/GH_DACON_2022_08/check.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     test_dataset \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'GH_Dataset' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "path = \"/home/inhamath/dacon\"\n",
    "\n",
    "with open(path + \"/GH_DACON_2022_08/train_dataset.pickle\", 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open(path + \"/GH_DACON_2022_08/test_dataset.pickle\", 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size)\n",
    "del train_dataset\n",
    "del test_dataset\n",
    "\n",
    "model = GH()\n",
    "model.load_state_dict(torch.load(\"/home/inhamath/dacon/GH_DACON_2022_08/model_state/50,0.0014.pt\"))\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "criterion = pointnetloss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\"\"\"\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        inputs, labels = data['pointcloud'].float(), data['category']\n",
    "        outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        all_preds += list(preds.numpy())\n",
    "        all_labels += list(labels.numpy())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060adaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
